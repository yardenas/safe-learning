defaults:
  - penalizer: lagrangian

name: sac
learning_rate: 3e-4
critic_learning_rate: 3e-4
cost_critic_learning_rate: 3e-4
discounting: 0.99
safety_discounting: 0.99
batch_size: 256
num_trajectories_per_env: 1
normalize_observations: True
reward_scaling: 1.0
tau: 0.005
min_replay_size: 0
max_replay_size: 1000000
grad_updates_per_step: 512
deterministic_eval: true
hidden_layer_sizes: [128, 128]
activation: swish
cost_penalty: null
propagation: standard
cost_q_transform: cvar
cvar_confidence: 0.95