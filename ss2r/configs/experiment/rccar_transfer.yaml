# @package _global_
defaults:
  - rccar_hardware
  - override /agent/data_collection: episodic
  - override /agent/penalizer: lagrangian
  - _self_

training:
  num_timesteps: 25000
  wandb_id: 7qm6mozf

agent:
  batch_size: 256
  min_replay_size: 1000
  max_replay_size: 1048576
  policy_hidden_layer_sizes: [64, 64]
  grad_updates_per_step: 2500
  learning_rate: 1e-5
  critic_learning_rate: 3e-4
  num_critic_updates_per_actor_update: 10