# @package _global_
defaults:
  - override /environment: cartpole
  - override /agent: ppo
  - override /agent/cost_robustness: ucb_cost
  - override /agent/propagation: ts1
  - _self_

training:
  num_timesteps: 60000000
  safe: true
  train_domain_randomization: true
  eval_domain_randomization: true
  safety_budget: 100
  num_eval_episodes: 1
  num_envs: 2048
  value_privileged: false
  policy_privileged: false

environment:
  train_params:
    gain: [0, 5]
    gear: [0., 0.]

  eval_params:
    gain: [0, 0]
    gear: [0., 300.]

agent:
  reward_scaling: 0.5
  normalize_observations: true
  unroll_length: 10
  num_minibatches: 32
  num_updates_per_batch: 16
  discounting: 0.99
  safety_discounting: 0.9
  learning_rate: 3e-4
  entropy_cost: 0.01
  batch_size: 1024
  safety_gae_lambda: 0.95
  penalizer:
    eta: 15.
  policy_hidden_layer_sizes: [128, 128, 128]
  value_hidden_layer_sizes: [128, 128, 128]
  activation: tanh
