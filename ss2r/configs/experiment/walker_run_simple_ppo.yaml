# @package _global_
defaults:
  - override /environment: walker
  - override /agent: ppo
  - _self_

# environment:
#   task_name: SafeWalkerRun

training:
  # num_timesteps: 150000000
  num_timesteps: 60000000
  safe: true
  train_domain_randomization: false
  eval_domain_randomization: false
  safety_budget: 100
  num_eval_episodes: 1
  num_envs: 2048

agent:
  reward_scaling: 10.0
  normalize_observations: true
  unroll_length: 30
  num_minibatches: 32
  num_updates_per_batch: 16
  discounting: 0.995
  safety_discounting: 0.99
  learning_rate: 0.001
  entropy_cost: 0.01
  batch_size: 1024
  safety_gae_lambda: 0.0
  penalizer:
    terminate: true
    penalty: 2
