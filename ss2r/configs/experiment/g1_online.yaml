# @package _global_
defaults:
  - g1_joystick
  - override /agent/data_collection: hardware
  - override /agent/penalizer: lagrangian
  - _self_

training:
  num_envs: 1
  num_eval_envs: 1
  num_timesteps: 25000
  num_evals: 5
  render: false
  wandb_id: 02anvfes
  safe: false

agent:
  min_replay_size: 1000
  max_replay_size: 500000
  grad_updates_per_step: 1250
  learning_rate: 1e-5
  critic_learning_rate: 3e-4
  num_critic_updates_per_actor_update: 20
  n_critics: 1
  n_heads: 10
  data_collection:
    wait_time_sec: 120
